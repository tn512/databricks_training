{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba18955d-056d-4896-9d41-a2dadfc94067",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Show Lineage for Delta Tables in Unity Catalog\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/uc/lineage/uc-lineage-slide.png?raw=true\" style=\"float:right; margin-left:10px\" width=\"700\"/>\n",
    "\n",
    "Unity Catalog captures runtime data lineage for any table to table operation executed on a Databricks cluster or SQL endpoint. Lineage operates across all languages (SQL, Python, Scala and R) and it can be visualized in the Data Explorer in near-real-time, and also retrieved via REST API.\n",
    "\n",
    "Lineage is available at two granularity levels:\n",
    "- Tables.\n",
    "- Columns (ideal to track GDPR dependencies).\n",
    "\n",
    "Lineage takes into account the Table ACLs present in Unity Catalog. If a user is not allowed to see a table at a certain point of the graph, its information are redacted, but they can still see that a upstream or downstream table is present.\n",
    "\n",
    "## Working with Lineage\n",
    "\n",
    "No modifications are needed to the existing code to generate the lineage. As long as you operate with tables saved in the Unity Catalog, Databricks will capture all lineage informations for you.\n",
    "\n",
    "Requirements:\n",
    "- Make sure you set `spark.databricks.dataLineage.enabled true`in your cluster setup.\n",
    "- Source and target tables must be registered in a Unity Catalog metastore to be eligible for lineage capture.\n",
    "- The data manipulation must be performed using Spark DataFrame language (python/SQL).\n",
    "- To view lineage, users must have the SELECT privilege on the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fa531f1-49fe-4d07-8e80-ceaa42e128a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./_resources/00-setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25907be0-d716-4224-ba62-c17716486949",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Create a Delta Table In Unity Catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "771f96c1-9183-4299-be3a-b82876df1741",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT CURRENT_CATALOG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d3ed632-1994-4d6b-972c-07841ae3454a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE IF NOT EXISTS menu (\n",
    "  recipe_id INT, \n",
    "  app STRING, \n",
    "  main STRING, \n",
    "  desert STRING\n",
    ");\n",
    "\n",
    "DELETE FROM menu;\n",
    "\n",
    "INSERT INTO menu (recipe_id, app, main, desert) \n",
    "VALUES (1,\"Ceviche\", \"Tacos\", \"Flan\"),\n",
    "       (2,\"Tomato Soup\", \"Souffle\", \"Creme Brulee\"),\n",
    "       (3,\"Chips\",\"Grilled Cheese\",\"Cheescake\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33d008bd-2a15-4c88-85d2-de35c8a1bffd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Create a Delta Table from the Previously Created One:\n",
    "\n",
    "To show dependancies between tables, we create a new one `AS SELECT` from the previous one, concatenating three columns into a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "734356d7-4e68-4032-b1fc-e43602ff000c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE IF NOT EXISTS dinner AS\n",
    "  SELECT recipe_id,\n",
    "         CONCAT(app, \" + \", main, \" + \", desert) AS full_menu\n",
    "  FROM menu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3f8ca9b-30e0-480c-a440-65f5b40c24a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "INSERT INTO dinner\n",
    "  SELECT recipe_id,\n",
    "          CONCAT(app, \" + \", main, \" + \", desert) AS full_menu\n",
    "    FROM menu;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "363e2732-1269-4b6d-9f25-4d277842ca3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Create a Delta Table as join from Two Other Tables:\n",
    "\n",
    "- We create a Dataframe with some random data formatted according to two columns, `id` and `recipe_id`\n",
    "- We save this Dataframe as a new table, `main.lineage.price`\n",
    "- We read as two Dataframes the previous two tables, `main.lineage.dinner` and `main.lineage.price`\n",
    "- We join them on `recipe_id` and save the result as a new Delta table `main.lineage.dinner_price`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "665dadac-3f68-4748-b2dc-1f4810b57cbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df = (spark.range(3)\n",
    "            .withColumn(\"price\", F.round(F.rand(seed=42) * 10, 2))\n",
    "            .withColumnRenamed(\"id\", \"recipe_id\"))\n",
    "\n",
    "(df.write\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(\"price\"))\n",
    "\n",
    "price = spark.read.table(\"price\")\n",
    "dinner = spark.read.table(\"dinner\")\n",
    "\n",
    "dinner_price = dinner.join(price, on=\"recipe_id\", how=\"inner\")\n",
    "dinner_price.write.mode(\"overwrite\").saveAsTable(\"dinner_price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a46168ad-085d-43d2-8f87-490ae6e96d96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM dinner_price;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e0813a5-da9e-4921-a937-76015ca3da7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Visualize Table Lineage:\n",
    "\n",
    "The Lineage can be visualized in the `Data Explorer` of the part of the Workspace dedicated to the `SQL Persona`.\n",
    "\n",
    "1. Select the `Catalog`\n",
    "1. Select the `Schema`\n",
    "1. Select the `Table`\n",
    "1. Select the `Lineage` tab on the right part of the page\n",
    "1. You can visualize the full lineage by pressing the `See Lineage Graph` button\n",
    "1. By default the graph is condensed. By clicking on the boxes you can expand them and visualize the full lineage.\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/uc/lineage/lineage-table.gif?raw=true\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8db2e6d4-a49b-49ff-89ab-4cdac8841a5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. Visualize Column Lineage:\n",
    "\n",
    "The Lineage is alos available for the Column. This is very useful to track column dependencies and be able to find GDPR, including by API.\n",
    "\n",
    "You can access the column lineage by clicking on any of the column name:\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/uc/lineage/lineage-column.gif?raw=true\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8e86c3d-b751-4615-ad98-c0739d26a16c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Existing Limitations\n",
    "- Streaming operations are not yet supported.\n",
    "\n",
    "- Lineage will not be captured when data is written directly to files in cloud storage even if a table is defined at that location (eg spark.write.save(“s3:/mybucket/mytable/”) will not produce lineage).\n",
    "\n",
    "- Lineage is not captured across workspaces (eg if a table A > table B transformation is performed in workspace 1 and table B > table C in workspace 2, each workspace will show a partial view of the lineage for table B).\n",
    "\n",
    "- Lineage is computed on a 90-day rolling window, meaning that lineage will not be displayed for tables that have not been modified in more than 90 days ago."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5029429968322282,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "00-UC-lineage",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
