{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8a82ee0-85e8-484f-989b-7c600fbddd8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.dropdown(\"reset_all_data\", \"false\", [\"true\", \"false\"], \"Reset all data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cff59f7-b2c9-4d03-a633-b271dc0b958c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ./00-global-setup-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03eca280-cd64-4d25-ba87-41152a0160e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "deffa3d4-a6bb-4551-8c37-f962f15da2d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "777c02f7-9c5c-4025-a3ba-7cc1e9a5a578",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"delta_learning\"\n",
    "schema = dbName = db = \"dev\"\n",
    "\n",
    "volume_name = \"delta_lake_raw_data\"\n",
    "volume_folder =  f\"/Volumes/{catalog}/{db}/{volume_name}\"\n",
    "\n",
    "reset_all_data = dbutils.widgets.get(\"reset_all_data\") == \"true\"\n",
    "\n",
    "DBDemos.setup_schema(catalog, db, reset_all_data, volume_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89a93df4-53ca-45af-9067-9b04847dbb3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_chkp_folder(folder):\n",
    "    import random\n",
    "    import string\n",
    "    randomCar = ''.join(random.choices(string.ascii_letters + string.digits, k=8))  # \n",
    "    return folder+'/checkpoint/streams/'+randomCar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7cdaf67f-6e7e-4be0-9e6d-4db13e2f03cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "folder = f\"/Volumes/{catalog}/{db}/{volume_name}\"\n",
    "load_data = reset_all_data or DBDemos.is_any_folder_empty([folder+\"/user_json\", folder+\"/user_parquet\"])\n",
    "\n",
    "if not load_data:\n",
    "    dbutils.notebook.exit('data already existing. Run with reset_all_data=true to force a data cleanup for your local demo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01caa759-6794-4afa-8569-8b5efae6169a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from faker import Faker\n",
    "from collections import OrderedDict \n",
    "import uuid\n",
    "\n",
    "fake = Faker()\n",
    "fake_firstname = F.udf(fake.first_name)\n",
    "fake_lastname = F.udf(fake.last_name)\n",
    "fake_email = F.udf(fake.ascii_company_email)\n",
    "fake_date = F.udf(lambda:fake.date_time_this_month().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "fake_address = F.udf(fake.address)\n",
    "\n",
    "df = spark.range(0, 10000)\n",
    "  \n",
    "df = df.withColumn(\"id\", F.monotonically_increasing_id())\n",
    "df = df.withColumn(\"creation_date\", fake_date())\n",
    "df = df.withColumn(\"creation_date\", F.to_timestamp(F.col(\"creation_date\")))\n",
    "df = df.withColumn(\"firstname\", fake_firstname())\n",
    "df = df.withColumn(\"lastname\", fake_lastname())\n",
    "df = df.withColumn(\"email\", fake_email())\n",
    "df = df.withColumn(\"address\", fake_address())\n",
    "df = df.withColumn(\"gender\", F.round(F.rand()+0.2).cast('int'))\n",
    "df = df.withColumn(\"age_group\", F.round(F.rand()*10).cast('int'))\n",
    "\n",
    "df.repartition(5).write.mode(\"overwrite\").format(\"json\").save(folder+\"/user_json\")\n",
    "df.repartition(5).write.mode(\"overwrite\").format(\"parquet\").save(folder+\"/user_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e257932a-80de-4894-9e8f-000054aea528",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"CREATE TABLE IF NOT EXISTS user_delta (\n",
    "            id BIGINT, creation_date TIMESTAMP, \n",
    "            firstname STRING, lastname STRING, \n",
    "            email STRING, address STRING, \n",
    "            gender INT, age_group INT)\n",
    "            \"\"\")\n",
    "\n",
    "spark.sql(\"ALTER TABLE user_delta \n",
    "           SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\")\n",
    "\n",
    "if not spark.catalog.tableExists(f\"{catalog}.{schema}.user_uniform\"):\n",
    "    spark.sql(\"\"\"\n",
    "                CREATE TABLE user_uniform ( \n",
    "                    id BIGINT, firstname STRING, \n",
    "                    lastname STRING, email STRING)\n",
    "                TBLPROPERTIES (\n",
    "                    'delta.universalFormat.enabledFormats' = 'iceberg',  \n",
    "                    'delta.enableIcebergCompatV2' = 'true')\n",
    "              \"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "00-setup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
