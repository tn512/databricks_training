{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1016adfb-f3bb-4db4-b5fd-364ca2f6c006",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Delta Lake internals\n",
    "<img src=\"https://pages.databricks.com/rs/094-YMS-629/images/delta-lake-logo-whitebackground.png\" style=\"width:200px; float: right\"/>\n",
    "\n",
    "Let's deep dive into Delta Lake internals.\n",
    "\n",
    "## Exploring delta structure\n",
    "\n",
    "Under the hood, Delta is composed of parquet files and a transactional log. Transactional log contains all the metadata operation. Databricks leverage this information to perform efficient data skipping at scale among other things.\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=data-engineering&org_id=3759185753378633&notebook=%2F05-Advanced-Delta-Lake-Internal&demo_name=delta-lake&event=VIEW&path=%2F_dbdemos%2Fdata-engineering%2Fdelta-lake%2F05-Advanced-Delta-Lake-Internal&version=1\">\n",
    "<!-- [metadata={\"description\":\"Quick introduction to Delta Lake. <br/><i>Use this content for quick Delta demo.</i>\",\n",
    " \"authors\":[\"quentin.ambard@databricks.com\"],\n",
    " \"db_resources\":{}}] -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b5b63f6-d973-43f2-8442-868f1b8fb7df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": null
    }
   },
   "source": [
    "### A cluster has been created for this demo\n",
    "To run this demo, just select the cluster `dbdemos-delta-lake-maynard` from the dropdown menu ([open cluster configuration](https://adb-3759185753378633.13.azuredatabricks.net/#setting/clusters/0526-040835-grmtve88/configuration)). <br />\n",
    "*Note: If the cluster was deleted after 30 days, you can re-create it with `dbdemos.create_cluster('delta-lake')` or re-install the demo: `dbdemos.install('delta-lake')`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dcc38256-826a-4b43-9d6a-8cb816f50ebb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Init the demo data"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ./_resources/00-setup $reset_all_data=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5531465f-5161-4d94-a9f5-323a40ad6bfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Exploring delta structure\n",
    "\n",
    "Delta is composed of parquet files and a transactional log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c56f75f-7f1c-4fb2-b865-9251c3db12bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "spark.table('user_delta').write.mode('overwrite').save(f'/Volumes/{catalog}/{schema}/{volume_name}/user_delta_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c311fee-3cd0-4da3-839d-e6fbc4724e2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "DESCRIBE DETAIL `delta`.`/Volumes/main/dbdemos_delta_lake/delta_lake_raw_data/user_delta_table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c65dc552-21f5-409b-ba35-5db68be94e14",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Delta is composed of parquet files"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "delta_folder = spark.sql(f\"DESCRIBE DETAIL `delta`.`/Volumes/{catalog}/{schema}/{volume_name}/user_delta_table`\").collect()[0]['location']\n",
    "print(delta_folder)\n",
    "display(dbutils.fs.ls(delta_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5ce5368-c4be-43fb-bdf7-8b7be88bbb43",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "And a transactional log"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(dbutils.fs.ls(delta_folder+\"/_delta_log\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bbe5e3d-ab99-4904-bb42-77389c91f59f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "commit_log = dbutils.fs.head(delta_folder+\"/_delta_log/00000000000000000000.json\", 10000)\n",
    "print(json.dumps(json.loads(commit_log.split('\\n')[0]), indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9145df24-4fe5-44ca-bdf2-8ba8b68758bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## OPTIMIZE in action\n",
    "Running an `OPTIMIZE` + `VACUUM` will re-order all our files.\n",
    "\n",
    "As you can see, we have multiple small parquet files in our folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ffd9e07-27c6-4f2a-b94d-6c89351c8802",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(dbutils.fs.ls(delta_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d324ef95-7190-4e1e-a8bb-9e51c4d5b74b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's OPTIMIZE our table to see how the engine will compact the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be1b0496-c3d0-4aa8-a158-305e3f9b6100",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "OPTIMIZE `delta`.`/Volumes/main/dbdemos_delta_lake/delta_lake_raw_data/user_delta_table`;\n",
    "-- as we vacuum with 0 hours, we need to remove the safety check:\n",
    "\n",
    "-- Note: commented out as this option isn't available on serverless compute for now - see ES-1302674\n",
    "-- set spark.databricks.delta.retentionDurationCheck.enabled = false;\n",
    "\n",
    "-- VACUUM `delta`.`/Volumes/main/dbdemos_delta_lake/delta_lake_raw_data/user_delta_table` retain 0 hours;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8a22aa9-2fe1-443d-b2aa-57c79ba623cf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Only one parquet file remains after the OPTIMIZE+VACUUM operation"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(dbutils.fs.ls(delta_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fae75a57-54da-4f68-aef7-0e168c097442",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "That's it! You know everything about Delta Lake!\n",
    "\n",
    "As next step, you learn more about Delta Live Table to simplify your ingestion pipeline: `dbdemos.install('delta-live-table')`\n",
    "\n",
    "Go back to [00-Delta-Lake-Introduction]($./00-Delta-Lake-Introduction)."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "05-Advanced-Delta-Lake-Internal",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
