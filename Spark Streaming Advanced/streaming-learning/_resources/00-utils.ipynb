{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cba1dc3-4c90-4e14-9245-9d90c83745f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.dropdown(\"reset_all_data\", \"false\", [\"true\", \"false\"], \"Reset all data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67763d17-55aa-49c9-90d6-7559a0ed4ff9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import collections\n",
    "import os\n",
    "\n",
    "class Utils():\n",
    "    @staticmethod\n",
    "    def setup_schema(catalog, db, reset_all_data, volume_name = None):\n",
    "        if reset_all_data:\n",
    "            print(f'clearing up volume named `{catalog}`.`{db}`.`{volume_name}`')\n",
    "            try:\n",
    "                spark.sql(f\"DROP VOLUME IF EXISTS `{catalog}`.`{db}`.`{volume_name}`\")\n",
    "                spark.sql(f\"DROP SCHEMA IF EXISTS `{catalog}`.`{db}` CASCADE\")\n",
    "            except Exception as e:\n",
    "                print(f'catalog `{catalog}` or schema `{db}` do not exist.  Skipping data reset')\n",
    "\n",
    "        def use_and_create_db(catalog, dbName, cloud_storage_path = None):\n",
    "            print(f\"USE CATALOG `{catalog}`\")\n",
    "            spark.sql(f\"USE CATALOG `{catalog}`\")\n",
    "            spark.sql(f\"\"\"create database if not exists `{dbName}` \"\"\")\n",
    "\n",
    "        assert catalog not in ['hive_metastore', 'spark_catalog'], \"This demo only support Unity. Please change your catalog name.\"\n",
    "        #If the catalog is defined, we force it to the given value and throw exception if not.\n",
    "        current_catalog = spark.sql(\"select current_catalog()\").collect()[0]['current_catalog()']\n",
    "        if current_catalog != catalog:\n",
    "            catalogs = [r['catalog'] for r in spark.sql(\"SHOW CATALOGS\").collect()]\n",
    "            if catalog not in catalogs:\n",
    "                spark.sql(f\"CREATE CATALOG IF NOT EXISTS `{catalog}` MANAGED LOCATION 'abfss://unity-catalog-storage@dbstoragefuavvebhyzyxm.dfs.core.windows.net/3759185753378633'\")\n",
    "                if catalog == 'dbdemos':\n",
    "                    spark.sql(f\"ALTER CATALOG `{catalog}` OWNER TO `account users`\")\n",
    "        \n",
    "        use_and_create_db(catalog, db)\n",
    "\n",
    "        if catalog == 'dbdemos':\n",
    "            try:\n",
    "                spark.sql(f\"GRANT CREATE, USAGE on DATABASE `{catalog}`.`{db}` TO `account users`\")\n",
    "                spark.sql(f\"ALTER SCHEMA `{catalog}`.`{db}` OWNER TO `account users`\")\n",
    "                for t in spark.sql(f'SHOW TABLES in {catalog}.{db}').collect():\n",
    "                    try:\n",
    "                        spark.sql(f'GRANT ALL PRIVILEGES ON TABLE {catalog}.{db}.{t[\"tableName\"]} TO `account users`')\n",
    "                        spark.sql(f'ALTER TABLE {catalog}.{db}.{t[\"tableName\"]} OWNER TO `account users`')\n",
    "                    except Exception as e:\n",
    "                        if \"NOT_IMPLEMENTED.TRANSFER_MATERIALIZED_VIEW_OWNERSHIP\" not in str(e) and \"STREAMING_TABLE_OPERATION_NOT_ALLOWED.UNSUPPORTED_OPERATION\" not in str(e) :\n",
    "                            print(f'WARN: Couldn t set table {catalog}.{db}.{t[\"tableName\"]} owner to account users, error: {e}')\n",
    "            except Exception as e:\n",
    "                print(\"Couldn't grant access to the schema to all users:\"+str(e))    \n",
    "\n",
    "        print(f\"using catalog.database `{catalog}`.`{db}`\")\n",
    "        spark.sql(f\"\"\"USE `{catalog}`.`{db}`\"\"\")    \n",
    "\n",
    "        if volume_name:\n",
    "            spark.sql(f'CREATE VOLUME IF NOT EXISTS {volume_name};')\n",
    "\n",
    "    @staticmethod\n",
    "    def wait_for_table(table_name, timeout_duration=120):\n",
    "        import time\n",
    "        i = 0\n",
    "        while not spark.catalog.tableExists(table_name) or spark.table(table_name).count() == 0:\n",
    "            time.sleep(1)\n",
    "            if i > timeout_duration:\n",
    "                raise Exception(f\"couldn't find table {table_name} or table is empty. Do you have data being generated to be consumed?\")\n",
    "            i += 1\n",
    "\n",
    "    @staticmethod\n",
    "    def get_active_streams(start_with = \"\"):\n",
    "        return [s for s in spark.streams.active if len(start_with) == 0 or (s.name is not None and s.name.startswith(start_with))]\n",
    "\n",
    "    @staticmethod\n",
    "    def stop_all_streams(start_with = \"\", sleep_time=0):\n",
    "        import time\n",
    "\n",
    "        time.sleep(sleep_time)\n",
    "        streams = Utils.get_active_streams(start_with)\n",
    "\n",
    "        if len(streams) > 0:\n",
    "            print(f\"Stopping {len(streams)} streams\")\n",
    "\n",
    "            for s in streams:\n",
    "                try:\n",
    "                    s.stop()\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "            print(f\"All stream stopped {'' if len(start_with) == 0 else f'(starting with: {start_with}.)'}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00-utils",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
